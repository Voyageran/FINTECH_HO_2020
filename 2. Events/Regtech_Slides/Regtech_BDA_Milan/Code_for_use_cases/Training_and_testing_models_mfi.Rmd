---
title: "Credit Risk in P2P lending through BDA part I"
prepared by: "FinTech HO2020 Project Consortium"
date: "29 March 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readr)
library(ggplot2)
library(plotrix)
library(rpart)
library(rpart.plot)
library(MASS)
library(caret)  
library(ROCR)
library(pROC)
library(rpart)
library(DescTools)
library(partykit)
library(randomForest)
library(ggpubr)
library(rattle)



rm(list=ls())

#setwd("C:/Users/brank/Google Drive/Pavia/NETWORK/September 2017/EU Project (code and scripts)/Code/Workshop")
#final_dataset_smes <- read_csv("final_dataset_smes.csv")
#setwd("C:/Users/sabrina.stella/Dropbox (modeFinance)/H2020/")
data_final_stand <- read_csv("final_dataset_mfi.csv")
data <- data_final_stand[-1]


```


## Structure and dimensions of the dataset
We start by investigating the structure and the dimensions of the dataset
```{r summary, echo=FALSE}
str(data)
dim(data)
head(data)
summary(data)
```

# Specify the type of variables
```{r change_type, echo=FALSE}
data$status = as.factor(data$status)
str(data)
```


# Investigate the variable status 
```{r status, echo=FALSE}
PercTable(data$status)
```


# Investigate the variable status
```{r status2, echo=FALSE}

counts <- table(data$status)  
pie(counts)  

slices <- table(data$status) 
lbls <- c("active", "default")
pie3D(slices,labels=lbls,
   main="Pie Chart of the Status Variable", explode=0.5, radius=.9, labelcex = 1.2,  start=0.7)

#ggplot(data, aes(x = factor(1), y=status,fill=factor(status)) ) + geom_bar(width = 1,stat="identity")+coord_polar(theta = "y")
```

# Training vs Testing Dataset (stratified)
```{r dataset_splitting, echo=FALSE}
set.seed(1234)
div <- createDataPartition(y = data$status, p = 0.7, list = F)

# Training Sample
data.train <- data[div, c(1:20)] # 70% here
data.test <- data[-div, c(1:20)] # rest of the 30% data goes here

PercTable(data$status)
PercTable(data.train$status)
PercTable(data.test$status)
```


#============= LOGIT MODEL WITH ALL VARIABLES ================#
# Fit1: Logit - Training the model
```{r logit, echo=FALSE}
fit1 <- glm(status ~ ., data=data.train,family=binomial())
summary(fit1)

plot(predict(fit1),residuals(fit1),col=c("blue","red")[1+(fit1)$y])
abline(h=0,lty=2,col="grey")
```

# Fit1: Logit - Significant variables with p-value < 0.05
```{r logit_pvalue, echo=FALSE}
significant.variables <- summary(fit1)$coeff[-1,4] < 0.05
significant.variables
summary(fit1)$coeff[-1,4]
names(significant.variables)[significant.variables == TRUE]
```

## Fit1: Logit - Odds ratios and 95% CI
```{r logit_odd, echo=FALSE}
exp(cbind(OR = coef(fit1), confint(fit1)))
#or 
#exp(cbind(OR = coef(fit1), confint.default(fit1)))
```


# Fit1: Logit - Prediction
## Fit1: Logit - ROC curve 
```{r logit_roc, echo=FALSE}
data.test$fit1_score <- predict(fit1,type='response',data.test)
fit1_pred <- prediction(data.test$fit1_score, data.test$status)
fit1_roc <- performance(fit1_pred, "tpr", "fpr")
plot(fit1_roc, lwd=1, colorize = TRUE, main = "Fit1: Logit - ROC Curve")
lines(x=c(0, 1), y=c(0, 1), col="black", lwd=1, lty=3)
```


## Fit1: Logit - Precision/Recall Curve
```{r logit_precision, echo=FALSE}
fit1_precision <- performance(fit1_pred, measure = "prec", x.measure = "rec")
plot(fit1_precision, main="Fit1: Logit - Precision vs Recall")
```

# Fit1:Logit - Confusion Matrix
```{r logit_confusion, echo=FALSE}
confusionMatrix(as.factor(round(data.test$fit1_score)), data.test$status)

```

# Fit1: Logit - Predictive Utility 
```{r logit_predictive, echo=FALSE}
fit1_auc <- performance(fit1_pred, measure = "auc")
fit1_gini <- (2*fit1_auc@y.values[[1]] - 1)
fit1_ks <- round(max(attr(fit1_roc, 'y.value')[[1]] - attr(fit1_roc, 'x.values')[[1]]), 2)
cat("AUC: ",fit1_auc@y.values[[1]]*100,"\tGini:", fit1_gini*100, "\tKS Statistic: ", fit1_ks*100,  "\n")
```



#============= LOGIT MODEL WITH VARIABLE SELECTION ================#
# Fit2: Logit - Training the model
```{r logit2_training, echo=FALSE}
step <- stepAIC(fit1, direction="both")
step$anova 

fit2 <- glm(status ~  ta_tl + current_ratio + ROI + ROE + turnover_assets1 + 
    turnover_assets2 + EBITDA_int_paid + EBITA_op_revenues + 
    DPO + DSO + turnover ,data=data.train,family=binomial())
summary(fit2)
```

## Fit2: Logit - Odds ratios and 95% CI
```{r logit2_odd, echo=FALSE}
exp(cbind(OR = coef(fit2), confint(fit2)))
```


# Fit2: Logit - Prediction
## Fit2: Logit - ROC curve 
```{r logit2_ROC, echo=FALSE}
data.test$fit2_score <- predict(fit2,type='response',data.test)
fit2_pred <- prediction(data.test$fit2_score, data.test$status)
fit2_roc <- performance(fit2_pred, "tpr", "fpr")
plot(fit2_roc, lwd=1, colorize = TRUE, main = "Fit2: Logit - ROC Curve")
lines(x=c(0, 1), y=c(0, 1), col="black", lwd=1, lty=3)
```


## Fit2: Logit - Precision/Recall Curve
```{r logit2_prec, echo=FALSE}
fit2_precision <- performance(fit2_pred, measure = "prec", x.measure = "rec")
plot(fit2_precision, main="Fit2: Logit - Precision vs Recall")
```

# Fit2:Logit - Confusion Matrix
```{r logit2_conf, echo=FALSE}
confusionMatrix(as.factor(round(data.test$fit2_score)), data.test$status)

```

# Fit2: Logit - Predictive Utility 
```{r logit2_performance, echo=FALSE}
fit2_auc <- performance(fit2_pred, measure = "auc")
fit2_gini <- (2*fit2_auc@y.values[[1]] - 1)
fit2_ks <- round(max(attr(fit2_roc, 'y.value')[[1]] - attr(fit2_roc, 'x.values')[[1]]), 2)
cat("AUC: ",fit2_auc@y.values[[1]]*100,"\tGini:", fit2_gini*100, "\tKS Statistic: ", fit2_ks*100,  "\n")
```

#================== CART ============================#
# Fit3: CART - Training the model
```{r cart, echo=FALSE}
fit3 <- rpart(status ~  ta_tl + current_ratio + ROI + ROE + turnover_assets1 + 
    turnover_assets2 + EBITDA_int_paid + EBITA_op_revenues + 
    DPO + DSO + turnover, data=data.train, method="class")
summary(fit3)
print(fit3)
```

# Fit3: CART - The Tree Structure
```{r pressure, echo=FALSE}
printcp(fit3)
plot(fit3, margin = 0.2, main="Fit3: CART Tree")
text(fit3, cex=0.8)
prp(fit3,type=2,extra=1,  main="Fit3: CART Tree")
```

# Fit3: CART - The Tree Structure
```{r pressure_2, echo=FALSE}
fancyRpartPlot(fit3)
```


## Fit3: CART - Prediction
## Fit3: CART - ROC curve 
```{r Prediction, echo=FALSE}
data.test$fit3_score <- predict(fit3, data.test, type="prob")
fit3_pred <- prediction(data.test$fit3_score[,2], data.test$status)
fit3_roc <- performance(fit3_pred, "tpr", "fpr")
plot(fit3_roc, lwd=1, colorize = TRUE, main = "Fit3: CART - ROC Curve")
lines(x=c(0, 1), y=c(0, 1), col="black", lwd=1, lty=3)
```

## Fit3: CART - Precision/Recall Curve
```{r pressure_3, echo=FALSE}
fit3_precision <- performance(fit3_pred, measure = "prec", x.measure = "rec")
plot(fit3_precision, main="Fit3: CART - Precision vs Recall")
```

# Fit3:CART - Confusion Matrix
```{r pressure_4, echo=FALSE}
confusionMatrix(as.factor(round(data.test$fit3_score[,2])), data.test$status)
```

# Fit3: CART - Predictive Utility 
```{r pressure_5, echo=FALSE}
fit3_auc <- performance(fit3_pred, measure = "auc")
fit3_gini <- (2*fit3_auc@y.values[[1]] - 1)
fit3_ks <- round(max(attr(fit3_roc, 'y.value')[[1]] - attr(fit3_roc, 'x.values')[[1]]), 2)
cat("AUC: ",fit3_auc@y.values[[1]]*100,"\tGini:", fit3_gini*100, "\tKS Statistic: ", fit3_ks*100,  "\n")
```


#===================== RANDOM FOREST ======================#
# RF: Training the model
```{r pressure_6, echo=FALSE}
fit4 <- randomForest(status ~  ta_tl + current_ratio + ROI + ROE + turnover_assets1 + 
    turnover_assets2 + EBITDA_int_paid + EBITA_op_revenues + 
    DPO + DSO + turnover , data=data.train, mtry=2, ntree=1000, 
                      keep.forest=TRUE, importance=TRUE)
summary(fit4)
print(fit4)
```

# Fit4: RF - Plot variable importance
```{r pressure_7, echo=FALSE}
varImpPlot(fit4, main="Fit4: RF - Variable Importance")
```

## Fit4: RF - Prediction
## Fit4: RF - ROC curve 
```{r pressure_8, echo=FALSE}
data.test$fit4_score <- predict(fit4, data.test, type="prob")
fit4_pred <- prediction(data.test$fit4_score[,2], data.test$status)
fit4_roc <- performance(fit4_pred, "tpr", "fpr")
plot(fit4_roc, lwd=1, colorize = TRUE, main = "Fit4: RF - ROC Curve")
lines(x=c(0, 1), y=c(0, 1), col="black", lwd=1, lty=3)
```

## Fit4: RF - Precision/Recall Curve
```{r pressure_9, echo=FALSE}
fit4_precision <- performance(fit4_pred, measure = "prec", x.measure = "rec")
plot(fit4_precision, main="Fit4: RF - Precision vs Recall")
```

# Fit4:RF - Confusion Matrix
```{r pressure_10, echo=FALSE}
confusionMatrix(as.factor(round(data.test$fit4_score[,2])), data.test$status)
```

# Fit4: RF - Predictive Utility 
```{r pressure_11, echo=FALSE}
fit4_auc <- performance(fit4_pred, measure = "auc")
fit4_gini <- (2*fit4_auc@y.values[[1]] - 1)
fit4_ks <- round(max(attr(fit4_roc, 'y.value')[[1]] - attr(fit4_roc, 'x.values')[[1]]), 2)
cat("AUC: ",fit4_auc@y.values[[1]]*100,"\tGini:", fit4_gini*100, "\tKS Statistic: ", fit4_ks*100,  "\n")
```


#Compare ROC Performance of Models
```{r pressure_12, echo=FALSE}
plot(fit1_roc, col='blue', lwd=1,main='ROCs: Model Performance Comparision - MST') # logit
plot(fit2_roc, col='black',lwd=1, add=TRUE); # logit with step
plot(fit3_roc, col='green',lwd=1, add=TRUE) #CART
plot(fit4_roc, col='yellow',lwd=1, add=TRUE) #RF
legend(0.6,0.5,
       c('Logit_All Var','Logit_Step', 'CART', 'RF'),
       col=c('blue','black', 'green', 'yellow', 'red'),
       lwd=3)
```
